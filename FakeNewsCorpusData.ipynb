{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecbf4e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary BEFORE stop-word removal: 194649\n",
      "Total vocabulary AFTER stop-word removal: 194503\n",
      "Reduction Rate AFTER stop-word removal: 0.08%\n",
      "Total vocabulary AFTER stemming: 154535\n",
      "Reduction Rate AFTER stemming): 20.55%\n",
      "Saved: cleaned_chunk_0.csv\n",
      "Total vocabulary BEFORE stop-word removal: 200181\n",
      "Total vocabulary AFTER stop-word removal: 200040\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 160735\n",
      "Reduction Rate AFTER stemming): 19.65%\n",
      "Saved: cleaned_chunk_1.csv\n",
      "Total vocabulary BEFORE stop-word removal: 198293\n",
      "Total vocabulary AFTER stop-word removal: 198151\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 158444\n",
      "Reduction Rate AFTER stemming): 20.04%\n",
      "Saved: cleaned_chunk_2.csv\n",
      "Total vocabulary BEFORE stop-word removal: 190468\n",
      "Total vocabulary AFTER stop-word removal: 190324\n",
      "Reduction Rate AFTER stop-word removal: 0.08%\n",
      "Total vocabulary AFTER stemming: 151542\n",
      "Reduction Rate AFTER stemming): 20.38%\n",
      "Saved: cleaned_chunk_3.csv\n",
      "Total vocabulary BEFORE stop-word removal: 199262\n",
      "Total vocabulary AFTER stop-word removal: 199120\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 159652\n",
      "Reduction Rate AFTER stemming): 19.82%\n",
      "Saved: cleaned_chunk_4.csv\n",
      "Total vocabulary BEFORE stop-word removal: 196010\n",
      "Total vocabulary AFTER stop-word removal: 195869\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 156239\n",
      "Reduction Rate AFTER stemming): 20.23%\n",
      "Saved: cleaned_chunk_5.csv\n",
      "Total vocabulary BEFORE stop-word removal: 190363\n",
      "Total vocabulary AFTER stop-word removal: 190219\n",
      "Reduction Rate AFTER stop-word removal: 0.08%\n",
      "Total vocabulary AFTER stemming: 150703\n",
      "Reduction Rate AFTER stemming): 20.77%\n",
      "Saved: cleaned_chunk_6.csv\n",
      "Total vocabulary BEFORE stop-word removal: 193121\n",
      "Total vocabulary AFTER stop-word removal: 192981\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 154128\n",
      "Reduction Rate AFTER stemming): 20.13%\n",
      "Saved: cleaned_chunk_7.csv\n",
      "Total vocabulary BEFORE stop-word removal: 196933\n",
      "Total vocabulary AFTER stop-word removal: 196792\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 156804\n",
      "Reduction Rate AFTER stemming): 20.32%\n",
      "Saved: cleaned_chunk_8.csv\n",
      "Total vocabulary BEFORE stop-word removal: 200718\n",
      "Total vocabulary AFTER stop-word removal: 200578\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 162159\n",
      "Reduction Rate AFTER stemming): 19.15%\n",
      "Saved: cleaned_chunk_9.csv\n",
      "Total vocabulary BEFORE stop-word removal: 194677\n",
      "Total vocabulary AFTER stop-word removal: 194532\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 155848\n",
      "Reduction Rate AFTER stemming): 19.89%\n",
      "Saved: cleaned_chunk_10.csv\n",
      "Total vocabulary BEFORE stop-word removal: 185452\n",
      "Total vocabulary AFTER stop-word removal: 185313\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 147169\n",
      "Reduction Rate AFTER stemming): 20.58%\n",
      "Saved: cleaned_chunk_11.csv\n",
      "Total vocabulary BEFORE stop-word removal: 192538\n",
      "Total vocabulary AFTER stop-word removal: 192398\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 153661\n",
      "Reduction Rate AFTER stemming): 20.13%\n",
      "Saved: cleaned_chunk_12.csv\n",
      "Total vocabulary BEFORE stop-word removal: 193468\n",
      "Total vocabulary AFTER stop-word removal: 193327\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 154882\n",
      "Reduction Rate AFTER stemming): 19.89%\n",
      "Saved: cleaned_chunk_13.csv\n",
      "Total vocabulary BEFORE stop-word removal: 194838\n",
      "Total vocabulary AFTER stop-word removal: 194696\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 155850\n",
      "Reduction Rate AFTER stemming): 19.95%\n",
      "Saved: cleaned_chunk_14.csv\n",
      "Total vocabulary BEFORE stop-word removal: 195697\n",
      "Total vocabulary AFTER stop-word removal: 195555\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 157082\n",
      "Reduction Rate AFTER stemming): 19.67%\n",
      "Saved: cleaned_chunk_15.csv\n",
      "Total vocabulary BEFORE stop-word removal: 201557\n",
      "Total vocabulary AFTER stop-word removal: 201414\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 162469\n",
      "Reduction Rate AFTER stemming): 19.34%\n",
      "Saved: cleaned_chunk_16.csv\n",
      "Total vocabulary BEFORE stop-word removal: 203862\n",
      "Total vocabulary AFTER stop-word removal: 203723\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 164266\n",
      "Reduction Rate AFTER stemming): 19.37%\n",
      "Saved: cleaned_chunk_17.csv\n",
      "Total vocabulary BEFORE stop-word removal: 198468\n",
      "Total vocabulary AFTER stop-word removal: 198324\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 158942\n",
      "Reduction Rate AFTER stemming): 19.86%\n",
      "Saved: cleaned_chunk_18.csv\n",
      "Total vocabulary BEFORE stop-word removal: 189427\n",
      "Total vocabulary AFTER stop-word removal: 189285\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 150213\n",
      "Reduction Rate AFTER stemming): 20.64%\n",
      "Saved: cleaned_chunk_19.csv\n",
      "Total vocabulary BEFORE stop-word removal: 194929\n",
      "Total vocabulary AFTER stop-word removal: 194786\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 155385\n",
      "Reduction Rate AFTER stemming): 20.23%\n",
      "Saved: cleaned_chunk_20.csv\n",
      "Total vocabulary BEFORE stop-word removal: 207845\n",
      "Total vocabulary AFTER stop-word removal: 207701\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 167668\n",
      "Reduction Rate AFTER stemming): 19.27%\n",
      "Saved: cleaned_chunk_21.csv\n",
      "Total vocabulary BEFORE stop-word removal: 210579\n",
      "Total vocabulary AFTER stop-word removal: 210436\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 169691\n",
      "Reduction Rate AFTER stemming): 19.36%\n",
      "Saved: cleaned_chunk_22.csv\n",
      "Total vocabulary BEFORE stop-word removal: 200852\n",
      "Total vocabulary AFTER stop-word removal: 200710\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 161844\n",
      "Reduction Rate AFTER stemming): 19.36%\n",
      "Saved: cleaned_chunk_23.csv\n",
      "Total vocabulary BEFORE stop-word removal: 192574\n",
      "Total vocabulary AFTER stop-word removal: 192432\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 153530\n",
      "Reduction Rate AFTER stemming): 20.22%\n",
      "Saved: cleaned_chunk_24.csv\n",
      "Total vocabulary BEFORE stop-word removal: 191382\n",
      "Total vocabulary AFTER stop-word removal: 191242\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 152070\n",
      "Reduction Rate AFTER stemming): 20.48%\n",
      "Saved: cleaned_chunk_25.csv\n",
      "Total vocabulary BEFORE stop-word removal: 196095\n",
      "Total vocabulary AFTER stop-word removal: 195954\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 156371\n",
      "Reduction Rate AFTER stemming): 20.20%\n",
      "Saved: cleaned_chunk_26.csv\n",
      "Total vocabulary BEFORE stop-word removal: 188092\n",
      "Total vocabulary AFTER stop-word removal: 187947\n",
      "Reduction Rate AFTER stop-word removal: 0.08%\n",
      "Total vocabulary AFTER stemming: 149942\n",
      "Reduction Rate AFTER stemming): 20.22%\n",
      "Saved: cleaned_chunk_27.csv\n",
      "Total vocabulary BEFORE stop-word removal: 195113\n",
      "Total vocabulary AFTER stop-word removal: 194970\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 155897\n",
      "Reduction Rate AFTER stemming): 20.04%\n",
      "Saved: cleaned_chunk_28.csv\n",
      "Total vocabulary BEFORE stop-word removal: 188974\n",
      "Total vocabulary AFTER stop-word removal: 188833\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 149774\n",
      "Reduction Rate AFTER stemming): 20.68%\n",
      "Saved: cleaned_chunk_29.csv\n",
      "Total vocabulary BEFORE stop-word removal: 193944\n",
      "Total vocabulary AFTER stop-word removal: 193803\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 154500\n",
      "Reduction Rate AFTER stemming): 20.28%\n",
      "Saved: cleaned_chunk_30.csv\n",
      "Total vocabulary BEFORE stop-word removal: 193725\n",
      "Total vocabulary AFTER stop-word removal: 193584\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 154022\n",
      "Reduction Rate AFTER stemming): 20.44%\n",
      "Saved: cleaned_chunk_31.csv\n",
      "Total vocabulary BEFORE stop-word removal: 192182\n",
      "Total vocabulary AFTER stop-word removal: 192043\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary AFTER stemming: 152895\n",
      "Reduction Rate AFTER stemming): 20.39%\n",
      "Saved: cleaned_chunk_32.csv\n",
      "Total vocabulary BEFORE stop-word removal: 194096\n",
      "Total vocabulary AFTER stop-word removal: 193954\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 154591\n",
      "Reduction Rate AFTER stemming): 20.30%\n",
      "Saved: cleaned_chunk_33.csv\n",
      "Total vocabulary BEFORE stop-word removal: 198704\n",
      "Total vocabulary AFTER stop-word removal: 198564\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 159457\n",
      "Reduction Rate AFTER stemming): 19.69%\n",
      "Saved: cleaned_chunk_34.csv\n",
      "Total vocabulary BEFORE stop-word removal: 194015\n",
      "Total vocabulary AFTER stop-word removal: 193873\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 154941\n",
      "Reduction Rate AFTER stemming): 20.08%\n",
      "Saved: cleaned_chunk_35.csv\n",
      "Total vocabulary BEFORE stop-word removal: 196395\n",
      "Total vocabulary AFTER stop-word removal: 196252\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 156390\n",
      "Reduction Rate AFTER stemming): 20.31%\n",
      "Saved: cleaned_chunk_36.csv\n",
      "Total vocabulary BEFORE stop-word removal: 199470\n",
      "Total vocabulary AFTER stop-word removal: 199326\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 159561\n",
      "Reduction Rate AFTER stemming): 19.95%\n",
      "Saved: cleaned_chunk_37.csv\n",
      "Total vocabulary BEFORE stop-word removal: 196101\n",
      "Total vocabulary AFTER stop-word removal: 195959\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 156443\n",
      "Reduction Rate AFTER stemming): 20.17%\n",
      "Saved: cleaned_chunk_38.csv\n",
      "Total vocabulary BEFORE stop-word removal: 198491\n",
      "Total vocabulary AFTER stop-word removal: 198350\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 158643\n",
      "Reduction Rate AFTER stemming): 20.02%\n",
      "Saved: cleaned_chunk_39.csv\n",
      "Total vocabulary BEFORE stop-word removal: 195647\n",
      "Total vocabulary AFTER stop-word removal: 195505\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 156428\n",
      "Reduction Rate AFTER stemming): 19.99%\n",
      "Saved: cleaned_chunk_40.csv\n",
      "Total vocabulary BEFORE stop-word removal: 192197\n",
      "Total vocabulary AFTER stop-word removal: 192057\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 153486\n",
      "Reduction Rate AFTER stemming): 20.08%\n",
      "Saved: cleaned_chunk_41.csv\n",
      "Total vocabulary BEFORE stop-word removal: 191697\n",
      "Total vocabulary AFTER stop-word removal: 191554\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 152867\n",
      "Reduction Rate AFTER stemming): 20.20%\n",
      "Saved: cleaned_chunk_42.csv\n",
      "Total vocabulary BEFORE stop-word removal: 192523\n",
      "Total vocabulary AFTER stop-word removal: 192378\n",
      "Reduction Rate AFTER stop-word removal: 0.08%\n",
      "Total vocabulary AFTER stemming: 153246\n",
      "Reduction Rate AFTER stemming): 20.34%\n",
      "Saved: cleaned_chunk_43.csv\n",
      "Total vocabulary BEFORE stop-word removal: 186387\n",
      "Total vocabulary AFTER stop-word removal: 186245\n",
      "Reduction Rate AFTER stop-word removal: 0.08%\n",
      "Total vocabulary AFTER stemming: 148021\n",
      "Reduction Rate AFTER stemming): 20.52%\n",
      "Saved: cleaned_chunk_44.csv\n",
      "Total vocabulary BEFORE stop-word removal: 192289\n",
      "Total vocabulary AFTER stop-word removal: 192146\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 153889\n",
      "Reduction Rate AFTER stemming): 19.91%\n",
      "Saved: cleaned_chunk_45.csv\n",
      "Total vocabulary BEFORE stop-word removal: 189564\n",
      "Total vocabulary AFTER stop-word removal: 189423\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 151138\n",
      "Reduction Rate AFTER stemming): 20.21%\n",
      "Saved: cleaned_chunk_46.csv\n",
      "Total vocabulary BEFORE stop-word removal: 187289\n",
      "Total vocabulary AFTER stop-word removal: 187149\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 148860\n",
      "Reduction Rate AFTER stemming): 20.46%\n",
      "Saved: cleaned_chunk_47.csv\n",
      "Total vocabulary BEFORE stop-word removal: 191824\n",
      "Total vocabulary AFTER stop-word removal: 191683\n",
      "Reduction Rate AFTER stop-word removal: 0.07%\n",
      "Total vocabulary AFTER stemming: 153053\n",
      "Reduction Rate AFTER stemming): 20.15%\n",
      "Saved: cleaned_chunk_48.csv\n",
      "Total vocabulary BEFORE stop-word removal: 157473\n",
      "Total vocabulary AFTER stop-word removal: 157334\n",
      "Reduction Rate AFTER stop-word removal: 0.09%\n",
      "Total vocabulary AFTER stemming: 123377\n",
      "Reduction Rate AFTER stemming): 21.58%\n",
      "Saved: cleaned_chunk_49.csv\n",
      "Saved the CSV into CLEANED chunk.csv files\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CLEAN BIG DATA FILES (995,000_rows.csv for example...)\n",
    "\n",
    "- input: CSV-file\n",
    "- output: new csv files, splitted in chunks, for easier access (cause of size). Saved at 'FakeNewsCorpus_chunks/'.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from CleanData import *\n",
    "import os\n",
    "\n",
    "\n",
    "df = pd.read_csv('995,000_rows.csv', chunksize=20000)\n",
    "\n",
    "for i, chunk in enumerate(df):\n",
    "    temp_input_csv = f\"TEMPORARY_{i}.csv\"                    # Temporary input filename\n",
    "    cleaned_csv = f\"cleaned_chunk_{i}.csv\"                   # Output cleaned chunk filename\n",
    "    \n",
    "    chunk.to_csv(temp_input_csv, index=False)                # Save chunk as temp_input.CSV\n",
    "    full_cleaning(temp_input_csv, cleaned_csv)               # 'Full_Cleaning' function\n",
    "    \n",
    "    os.remove(temp_input_csv)                                # Remove 'temp' after use\n",
    "\n",
    "print(\"Saved the CSV into CLEANED chunk.csv files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f464ff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 50 CSV files into 'FakeNewsCorpus_chunks/merged_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MERGE ALL CLEANED_CHUNKS.csv files into a single CSV file again.\n",
    "\n",
    "- input: CSV-files (e.g: all the chunks from a specific folder)\n",
    "- output: A single merged CSV file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Step 1: Get all CSV files (CHUNKS)\n",
    "csv_files = glob.glob(\"FakeNewsCorpus_chunks/cleaned_chunk_*.csv\")\n",
    "\n",
    "# Step 2: Load and stack all CSV files into a single CSV\n",
    "df_combined = pd.concat([pd.read_csv(f) for f in csv_files])\n",
    "\n",
    "# Step 3: Save the merged CSV\n",
    "df_combined.to_csv(\"FakeNewsCorpus_chunks/merged_cleaned.csv\", index=False)\n",
    "\n",
    "print(f\"Merged {len(csv_files)} CSV files into 'FakeNewsCorpus_chunks/merged_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6dd038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "SET ALL TYPES TO RELIABLE OR FAKE\n",
    "\"\"\"\n",
    "from Model import group_types\n",
    "df = group_types(\"operation_csv_files/merged_cleaned.csv\", \"updated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb051d",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# Exploring the dataset (observations and discoveries)\n",
    "# -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e36ca1",
   "metadata": {},
   "source": [
    "### 1) Hvis $\\text{['source']}$ er en given variabel ($\\text{eks: nytimes}$), så er sandsynligheden at $\\text{['type']} == \\text{reliable}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b45946c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>political</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>political</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>unreliable</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>political</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>reliable</td>\n",
       "      <td>webhose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>reliable</td>\n",
       "      <td>webhose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>political</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>political</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>clickbait</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>clickbait</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>junksci</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>reliable</td>\n",
       "      <td>webhose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>fake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>reliable</td>\n",
       "      <td>webhose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>political</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>rumor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>political</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>clickbait</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>reliable</td>\n",
       "      <td>webhose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>clickbait</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>junksci</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>rumor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>reliable</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>political</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type   source\n",
       "1000  conspiracy      NaN\n",
       "1001        bias      NaN\n",
       "1002   political      NaN\n",
       "1003    reliable  nytimes\n",
       "1004        bias      NaN\n",
       "1005   political      NaN\n",
       "1006    reliable  nytimes\n",
       "1007        bias      NaN\n",
       "1008         NaN      NaN\n",
       "1009  unreliable      NaN\n",
       "1010        bias      NaN\n",
       "1011    reliable  nytimes\n",
       "1012   political      NaN\n",
       "1013    reliable  webhose\n",
       "1014    reliable  webhose\n",
       "1015   political      NaN\n",
       "1016   political      NaN\n",
       "1017   clickbait      NaN\n",
       "1018   clickbait      NaN\n",
       "1019    reliable  nytimes\n",
       "1020     junksci      NaN\n",
       "1021         NaN      NaN\n",
       "1022  conspiracy      NaN\n",
       "1023    reliable  webhose\n",
       "1024  conspiracy      NaN\n",
       "1025        fake      NaN\n",
       "1026    reliable  nytimes\n",
       "1027         NaN      NaN\n",
       "1028    reliable  nytimes\n",
       "1029        bias      NaN\n",
       "1030    reliable  webhose\n",
       "1031   political      NaN\n",
       "1032       rumor      NaN\n",
       "1033   political      NaN\n",
       "1034    reliable  nytimes\n",
       "1035     unknown      NaN\n",
       "1036    reliable  nytimes\n",
       "1037        bias      NaN\n",
       "1038  conspiracy      NaN\n",
       "1039        bias      NaN\n",
       "1040    reliable  nytimes\n",
       "1041   clickbait      NaN\n",
       "1042        bias      NaN\n",
       "1043    reliable  webhose\n",
       "1044    reliable  nytimes\n",
       "1045   clickbait      NaN\n",
       "1046  conspiracy      NaN\n",
       "1047    reliable  nytimes\n",
       "1048     junksci      NaN\n",
       "1049    reliable  nytimes\n",
       "1050        bias      NaN\n",
       "1051       rumor      NaN\n",
       "1052  conspiracy      NaN\n",
       "1053  conspiracy      NaN\n",
       "1054  conspiracy      NaN\n",
       "1055         NaN      NaN\n",
       "1056    reliable  nytimes\n",
       "1057        bias      NaN\n",
       "1058    reliable  nytimes\n",
       "1059   political      NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for chunk in df:\n",
    "    look = chunk[['type', 'source']]\n",
    "    display(look.head(60))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2946c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
